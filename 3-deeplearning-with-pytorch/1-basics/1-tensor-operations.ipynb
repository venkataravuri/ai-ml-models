{"cells":[{"cell_type":"markdown","metadata":{"id":"Tq358zBIhGDr"},"source":[" Reshaping operations are extremely important because the layers in a neural network only accept dimensional specific inputs."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4511,"status":"ok","timestamp":1699507590187,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"mVAXCZ0fiEkz"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":501,"status":"ok","timestamp":1699512277691,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"Lb2FcT-Bz0qJ"},"outputs":[],"source":["a = torch.arange(12)\n","a= a.reshape([3, 4])"]},{"cell_type":"markdown","metadata":{"id":"QwC7B_LKzvzp"},"source":["deduce the number of elements contained within the tensor. The number of elements inside a tensor (12 in our case) is equal to the product of the shape's component values."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699512124791,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"dO_n-UWc0IQp","outputId":"70cf649a-4a6d-45f1-93c9-939e3dc149bf"},"outputs":[{"data":{"text/plain":["tensor(12)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["torch.tensor(a.shape).prod(0)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":432,"status":"ok","timestamp":1699512146304,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"jZjBe-8u0RyX","outputId":"318c8c62-d324-4777-e190-d6f0e1544019"},"outputs":[{"data":{"text/plain":["12"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["a.numel()"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":524,"status":"ok","timestamp":1699512298330,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"x9oNS9_n0oZY","outputId":"e5ca6e35-c3f9-4a6f-f522-90820035bc3f"},"outputs":[{"data":{"text/plain":["tensor([[ 0,  1],\n","        [ 2,  3],\n","        [ 4,  5],\n","        [ 6,  7],\n","        [ 8,  9],\n","        [10, 11]])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["a.reshape(-1, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UkD9ewhI1Phn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yTBtmqf9lvME"},"source":["The reshape function in PyTorch gives the output tensor with same values and number of elements as the input tensor, it only alters the shape of the output tensor."]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":392,"status":"ok","timestamp":1699513798762,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"WQSAinwlmEaF","outputId":"7f2e802d-366e-4834-c6f1-91d464a868ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reshaped tensor: torch.Size([3, 3])\n","Tensor: tensor([[0, 1, 2],\n","        [3, 4, 5],\n","        [6, 7, 8]])\n"]},{"data":{"text/plain":["tensor([45, 56, 27, 34])"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.arange(9)\n","\n","r = torch.reshape(a, (3,3))\n","print(f'Reshaped tensor: {r.shape}')\n","print(f'Tensor: {r}')\n","\n","b = torch.tensor([[45, 56], [27, 34]])\n","torch.reshape(b, (-1,))"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":373,"status":"ok","timestamp":1699513800645,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"I4qp-U5A3Imu","outputId":"2810c8b3-cffc-4341-a9c5-f2962fc0fe7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0, 1, 2],\n","        [3, 4, 5],\n","        [6, 7, 8]])\n"]},{"data":{"text/plain":["tensor([[0],\n","        [1],\n","        [2],\n","        [3],\n","        [4],\n","        [5],\n","        [6],\n","        [7],\n","        [8]])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["print(r)\n","r.reshape(9,-1)"]},{"cell_type":"markdown","metadata":{"id":"-wlt2ouUhSBY"},"source":["For example, a 4D tensor of shape (batch_size, height, width, channels) cannot be fed into a fully connected layer that only accepts two dimensions. So we need to reshape the tensor to represent something like (batch_size, height * width * channels) which is a 2D tensor that can be used as an input to the fully connected layer."]},{"cell_type":"markdown","metadata":{"id":"w4qP-sSF7KW7"},"source":["view() reshapes the tensor without copying memory"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1699515104349,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"MCs2IXJw7MsL","outputId":"29fd68c0-54bd-4fed-d79f-7e9dfbe3eddf"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 3, 2, 4])\n","(24, 6, 2, 1)\n"]}],"source":["a = torch.rand(5, 4, 3, 2) # size (5, 4, 3, 2)\n","a_t = a.permute(0, 2, 3, 1) # size (5, 3, 2, 4)\n","print(a_t.shape)\n","\n","q = a.stride()\n","print(q)"]},{"cell_type":"markdown","metadata":{"id":"u9g89GK7hkHH"},"source":["Flatten Operation\n","\n","The Flatten operation is used to convert a multi-dimensional tensor into a one-dimensional tensor. This is done by taking all the elements of the tensor and arranging them in a single dimension.\n","\n","For example, if we have a tensor of shape (2, 3, 4), applying the Flatten operation would result in a tensor of shape (24,), which is basically a product of the individual elements.\n","\n","Pytorch provides `view` & `flatten` functions to flatten tensors."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331,"status":"ok","timestamp":1699507627456,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"TH_3aN32iVky","outputId":"100cb5c8-bf2d-4aa0-ed1d-35aaff015d2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original shape: torch.Size([16, 5, 5, 3])\n","Flattened shape: torch.Size([16, 75])\n"]}],"source":["x = torch.randn(16, 5, 5, 3)\n","print(f'Original shape: {x.shape}')\n","\n","x = x.view(16, 75) # ~ (16, 5*5*3)\n","print(f'Flattened shape: {x.shape}')"]},{"cell_type":"markdown","metadata":{"id":"emS0RudjjZyb"},"source":["Using `flatten` function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaX1BrmDjeiG"},"outputs":[],"source":["x = torch.randn(16, 5, 5, 3)\n","print(f'Original shape: {x.shape}')\n","\n","x = x.flatten()\n","print(f'Flattened shape: {x.shape}')"]},{"cell_type":"markdown","metadata":{"id":"151RkdY6j_c1"},"source":["This method creates a tensor x of shape of (16, 5, 5, 3) and then uses flatten function to reshape into 1D tensor. This gives us a tensor of shape (24,), which is product of dimensions of original tensor."]},{"cell_type":"markdown","metadata":{"id":"J_y4tjbDkX4m"},"source":["### Squeeze Operation\n","Removes dimensions of size 1 from a tensor. Useful when you have a tensor with unnecessary dimensions that you want to get rid off."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1699508168550,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"Kjo4dTWzk45G","outputId":"c7aead67-6f0f-4665-fdd9-fa2d2101bf08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original shape: torch.Size([3, 1, 1, 5])\n","Squeezed shape: torch.Size([3, 5])\n"]}],"source":["x = torch.randn(3, 1, 1, 5)\n","print(f'Original shape: {x.shape}')\n","\n","x = x.squeeze()\n","print(f'Squeezed shape: {x.shape}')"]},{"cell_type":"markdown","metadata":{"id":"yTvxWblRlOA9"},"source":["An advantage of this method is, the tensor can be unsqueezed again."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1699508281041,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"_i8_V3jJlTLF","outputId":"177a239c-1c9e-4feb-8d5d-cce86d81a999"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unsqueezed shape: torch.Size([3, 1, 1, 5])\n"]}],"source":["x = torch.randn(3, 5)\n","x = x.unsqueeze(1)\n","x = x.unsqueeze(2)\n","print(f'Unsqueezed shape: {x.shape}')"]},{"cell_type":"markdown","metadata":{"id":"BfgohcJw1QWY"},"source":[" it is possible to flatten only specific parts of a tensor. For example, suppose we have a tensor of shape [2,1,28,28] for a CNN. This means that we have a batch of 2 grayscale images with height and width dimensions of 28 x 28, respectively.\n","\n","Here, we can specifically flatten the two images. To get the following shape: [2,1,784]. We could also squeeze off the channel axes to get the following shape: [2,784]."]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":363,"status":"ok","timestamp":1699512743056,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"FXk4YlHc1alg"},"outputs":[],"source":["###  Concatenating tensors\n","\n","t1 = torch.tensor([\n","    [1,2],\n","    [3,4]\n","])\n","t2 = torch.tensor([\n","    [5,6],\n","    [7,8]\n","])"]},{"cell_type":"markdown","metadata":{"id":"NpYX-KV92tHB"},"source":["Combine t1 and t2 row-wise (axis-0) in the following way"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1699512783615,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"voKOVV4M2mc1","outputId":"f4538fdc-f049-4298-bd20-26f8138a1db9"},"outputs":[{"data":{"text/plain":["tensor([[1, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["torch.cat((t1, t2), dim=0)"]},{"cell_type":"markdown","metadata":{"id":"FQQQ6pd321dX"},"source":["Combine them column-wise (axis-1) like this:"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1699512847566,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"},"user_tz":-330},"id":"eysls_8_23J4","outputId":"3686bc8a-85f8-468a-e0f5-ea5dc983e59f"},"outputs":[{"data":{"text/plain":["tensor([[1, 2, 5, 6],\n","        [3, 4, 7, 8]])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["torch.cat((t1, t2), dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# https://learn.microsoft.com/en-us/training/modules/intro-machine-learning-pytorch/2-tensors\n","\n","%matplotlib inline\n","import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Numpy np_array value: \n"," [[1 2]\n"," [3 4]] \n","\n","Tensor x_np value: \n"," tensor([[1, 2],\n","        [3, 4]]) \n","\n","Numpy np_array after * 2 operation: \n"," [[2 4]\n"," [6 8]] \n","\n","Tensor x_np value after modifying numpy array: \n"," tensor([[2, 4],\n","        [6, 8]]) \n","\n"]}],"source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)\n","print(f\"Numpy np_array value: \\n {np_array} \\n\")\n","print(f\"Tensor x_np value: \\n {x_np} \\n\")\n","\n","np.multiply(np_array, 2, out=np_array)\n","\n","print(f\"Numpy np_array after * 2 operation: \\n {np_array} \\n\")\n","print(f\"Tensor x_np value after modifying numpy array: \\n {x_np} \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor: \n"," tensor([[0.3799, 0.0661],\n","        [0.8163, 0.2027]]) \n","\n"]}],"source":["x_ones = torch.ones_like(x_data) # returns the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # Overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Tensor: \n"," tensor([[0.1645, 0.6582, 0.5805],\n","        [0.1835, 0.8423, 0.2670]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]]) \n","\n"]}],"source":["shape = (2,3,)\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3, 4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'c:\\Python311\\python.exe' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'c:/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["if torch.cuda.is_available():\n","    tensor = tensor.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["First row:  tensor([1., 1., 1., 1.])\n","First column:  tensor([1., 1., 1., 1.])\n","Last column: tensor([1., 1., 1., 1.])\n","tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}],"source":["tensor = torch.ones(4, 4)\n","print('First row: ',tensor[0])\n","print('First column: ', tensor[:, 0])\n","print('Last column:', tensor[..., -1])\n","tensor[:,1] = 0\n","print(tensor)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}],"source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\n","print(t1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])"]},"metadata":{},"output_type":"display_data"}],"source":["y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(tensor)\n","torch.matmul(tensor, tensor.T, out=y3)\n","\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["12.0 <class 'float'>\n"]}],"source":["agg = tensor.sum()\n","agg_item = agg.item()\n","print(agg_item, type(agg_item))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n"]}],"source":["print(tensor, \"\\n\")\n","tensor.add_(5)\n","print(tensor)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n = np.ones(5)\n","t = torch.from_numpy(n)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["np.add(n, 1, out=n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOSg1CNirs92wGwId6XcpAm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
