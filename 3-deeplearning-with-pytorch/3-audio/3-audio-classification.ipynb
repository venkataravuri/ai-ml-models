{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNSQEP462k/HL75xiH7Z/jg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnGrRAlsGNAg","executionInfo":{"status":"ok","timestamp":1699369443015,"user_tz":-330,"elapsed":7443,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}},"outputId":"7923e6fe-152e-48c2-925e-4356f84e5ed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting soundata\n","  Downloading soundata-0.1.2-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jams\n","  Downloading jams-0.3.4.tar.gz (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting mir_eval\n","  Downloading mir_eval-0.7.tar.gz (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: jams, mir_eval\n","  Building wheel for jams (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jams: filename=jams-0.3.4-py3-none-any.whl size=64900 sha256=8430b442d162de11a6c7c6b141724c0d4de8a6040821e0c551e99ad9b76ae170\n","  Stored in directory: /root/.cache/pip/wheels/28/9a/f7/fb386b6bc5a75a3ef198a50e98b221e94a381472332b65cf24\n","  Building wheel for mir_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100703 sha256=ac16e61dc979d22b0585965b5d107334cb8e2f0542708f9b43c28d0795a4dd34\n","  Stored in directory: /root/.cache/pip/wheels/3e/2f/0d/dda9c4c77a170e21356b6afa2f7d9bb078338634ba05d94e3f\n","Successfully built jams mir_eval\n","Installing collected packages: soundata, mir_eval, jams\n","Successfully installed jams-0.3.4 mir_eval-0.7 soundata-0.1.2\n"]}],"source":["!pip install soundata jams mir_eval --no-dependencies"]},{"cell_type":"code","source":["import soundata\n","\n","dataset = soundata.initialize('urbansound8k')\n","dataset.download()\n","dataset.validate()\n","\n","example_clip = dataset.choice_clip()\n","print(example_clip)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CgeN5_9GR5P","executionInfo":{"status":"ok","timestamp":1699369873456,"user_tz":-330,"elapsed":424972,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}},"outputId":"43619a5c-5bc8-493f-abb7-2f3414c9a6e3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["5.61GB [04:38, 21.6MB/s]                            \n","100%|██████████| 1/1 [00:00<00:00, 212.73it/s]\n","100%|██████████| 8732/8732 [00:44<00:00, 195.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Clip(\n","  audio_path=\"/root/sound_datasets/urbansound8k/audio/fold1/203356-3-0-2.wav\",\n","  clip_id=\"203356-3-0-2\",\n","  audio: The clip's audio\n","            * np.ndarray - audio signal\n","            * float - sample rate,\n","  class_id: The clip's class id.\n","            * int - integer representation of the class label (0-9). See Dataset Info in the documentation for mapping,\n","  class_label: The clip's class label.\n","            * str - string class name: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music,\n","  fold: The clip's fold.\n","            * int - fold number (1-10) to which this clip is allocated. Use these folds for cross validation,\n","  freesound_end_time: The clip's end time in Freesound.\n","            * float - end time in seconds of the clip in the original freesound recording,\n","  freesound_id: The clip's Freesound ID.\n","            * str - ID of the freesound.org recording from which this clip was taken,\n","  freesound_start_time: The clip's start time in Freesound.\n","            * float - start time in seconds of the clip in the original freesound recording,\n","  salience: The clip's salience.\n","            * int - annotator estimate of class sailence in the clip: 1 = foreground, 2 = background,\n","  slice_file_name: The clip's slice filename.\n","            * str - The name of the audio file. The name takes the following format: [fsID]-[classID]-[occurrenceID]-[sliceID].wav,\n","  tags: The clip's tags.\n","            * annotations.Tags - tag (label) of the clip + confidence. In UrbanSound8K every clip has one tag,\n",")\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from pathlib import Path\n","\n","download_path = '/root/sound_datasets/urbansound8k'\n","\n","# Read metadata file\n","metadata_file = download_path + '/metadata/UrbanSound8K.csv'\n","df = pd.read_csv(metadata_file)\n","df.head()\n","\n","# Construct file path by concatenating fold and file name\n","df['relative_path'] = '/fold' + df['fold'].astype(str) + '/' + df['slice_file_name'].astype(str)\n","\n","df = df[['relative_path', 'classID']]\n","df.head()\n"],"metadata":{"id":"8xfosO8Xlu8H","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1699371980653,"user_tz":-330,"elapsed":415,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}},"outputId":"8c05a3c4-0075-4f17-a71b-b35346fc8243"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               relative_path  classID\n","0    /fold5/100032-3-0-0.wav        3\n","1  /fold5/100263-2-0-117.wav        2\n","2  /fold5/100263-2-0-121.wav        2\n","3  /fold5/100263-2-0-126.wav        2\n","4  /fold5/100263-2-0-137.wav        2"],"text/html":["\n","  <div id=\"df-295371ec-cbc6-4da0-b3ed-d2652d7de6db\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>relative_path</th>\n","      <th>classID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/fold5/100032-3-0-0.wav</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/fold5/100263-2-0-117.wav</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/fold5/100263-2-0-121.wav</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/fold5/100263-2-0-126.wav</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/fold5/100263-2-0-137.wav</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-295371ec-cbc6-4da0-b3ed-d2652d7de6db')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-295371ec-cbc6-4da0-b3ed-d2652d7de6db button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-295371ec-cbc6-4da0-b3ed-d2652d7de6db');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-84f35f9d-d876-4224-a5bb-3b70c5e1475e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84f35f9d-d876-4224-a5bb-3b70c5e1475e')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-84f35f9d-d876-4224-a5bb-3b70c5e1475e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["from re import A\n","from numpy.core.numerictypes import maximum_sctype\n","from numpy.core.overrides import ARRAY_FUNCTION_ENABLED\n","import math, random\n","import torch\n","import torchaudio\n","from torchaudio import transforms\n","from IPython.display import Audio\n","\n","\n","class AudioUtil():\n","\n","  @staticmethod\n","  def open(audio_file):\n","    sig, sr = torchaudio.load(audio_file)\n","    return (sig, sr)\n","\n","\n","  @staticmethod\n","  def rechannel(aud, new_channel):\n","    sig, sr = aud\n","\n","    if (sig.shape[0] == new_channel):\n","      # Nothing to do\n","      return aud\n","\n","    if (new_channel == 1):\n","      # Convert from stereo to mono by selecting only the first channel\n","      resig = sig[:1, :]\n","    else:\n","      # Convert from mon to stereo by duplicating the first channel\n","      resig = torch.cat([sig, sig])\n","\n","    return ((resig, sr))\n","\n","\n","  @staticmethod\n","  def resample(aud, newsr):\n","    sig, sr = aud\n","\n","    if (sr == newsr):\n","      # Nothing to do\n","      return aud\n","\n","    num_channels = sig.shape[0]\n","    # Resample first channel\n","    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1, :])\n","    if (num_channels > 1):\n","      # Resample the second channel and merge both channels\n","      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:, :])\n","      resig = torch.cat([resig, retwo])\n","\n","    return ((resig, newsr))\n","\n","  @staticmethod\n","  def pad_trunc(aud, max_ms):\n","    sig, sr = aud\n","    num_rows, sig_len = sig.shape\n","    max_len = sr//1000 * max_ms\n","\n","    if (sig_len > max_len):\n","      # Truncate the signale to the given length\n","      sig = sig[:, :max_len]\n","\n","    elif (sig_len < max_len):\n","      # Length of padding to add at the beginning and end of the signal\n","      pad_begin_len = random.randint(0, max_len - sig_len)\n","      pad_end_len = max_len - sig_len - pad_begin_len\n","\n","      # Pad with 0s\n","      pad_begin = torch.zeros((num_rows, pad_begin_len))\n","      pad_end = torch.zeros((num_rows, pad_end_len))\n","\n","      sig = torch.cat((pad_begin, sig, pad_end), 1)\n","\n","    return (sig, sr)\n","\n","\n","  @staticmethod\n","  def time_shift(aud, shift_limit):\n","    sig, sr = aud\n","    _, sig_len = sig.shape\n","    shift_amt = int(random.random() * shift_limit * sig_len)\n","    return (sig.roll(shift_amt), sr)\n","\n","\n","  @staticmethod\n","  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n","    sig, sr = aud\n","    top_db = 80\n","\n","    # spec the sample [channel, n_mels, time], where channels is mono, stereio etc.\n","    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)\n","\n","    # Convert to decibels\n","    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n","    return (spec)\n","\n","  @staticmethod\n","  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n","    _, n_mels, n_steps = spec.shape\n","    mask_value = spec.mean()\n","    aug_spec = spec\n","\n","\n","    freq_mask_param = max_mask_pct * n_mels\n","    for _ in range(n_freq_masks):\n","      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n","\n","    time_mask_param = max_mask_pct * n_steps\n","    for _ in range(n_time_masks):\n","      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n","\n","\n","    return aug_spec"],"metadata":{"id":"bu_tMx6pmqDu","executionInfo":{"status":"ok","timestamp":1699371988951,"user_tz":-330,"elapsed":427,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, Dataset, random_split\n","import torchaudio\n","\n","class SoundDS(Dataset):\n","  def __init__(self, df, data_path):\n","    self.df = df\n","    self.data_path = str(data_path)\n","    self.duration = 4000\n","    self.sr = 44100\n","    self.channel = 2\n","    self.shift_pct = 0.4\n","\n","\n","  def __len__(self):\n","    return len(self.df)\n","\n","  def __getitem__(self, idx):\n","    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n","\n","    class_id = self.df.loc[idx, 'classID']\n","\n","    aud = AudioUtil.open(audio_file)\n","\n","    reaud = AudioUtil.resample(aud, self.sr)\n","\n","    rechan = AudioUtil.rechannel(reaud, self.channel)\n","\n","    dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n","\n","    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n","\n","    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n","\n","    aug_sgram = AudioUtil.spectro_gram(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n","\n","    return aug_sgram, class_id"],"metadata":{"id":"n56GPvFbsQjZ","executionInfo":{"status":"ok","timestamp":1699371995299,"user_tz":-330,"elapsed":384,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import random_split\n","\n","\n","data_path =\"/root/sound_datasets/urbansound8k/audio\"\n","\n","myds = SoundDS(df, data_path)\n","\n","\n","# Random split of 80:20 between training and validation\n","\n","num_items = len(myds)\n","num_train = round(num_items * 0.8)\n","num_val = num_items - num_train\n","\n","train_ds, val_ds = random_split(myds, [num_train, num_val])\n","\n","print(len(train_ds), len(val_ds))\n","\n","train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n","val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=True)\n"],"metadata":{"id":"Lx0yq9kLGwB2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699371999289,"user_tz":-330,"elapsed":402,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}},"outputId":"c44faa1e-90da-4eb9-ea08-c8affa24441a"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["6986 1746\n"]}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","from torch.nn import init\n","from torch import nn\n","\n","\n","class AudioClassifier(nn.Module):\n","  def __iniit__(self):\n","    super().__init__()\n","    conv_layers = []\n","\n","    self.conv1 = nn.Conv2d(2, 8, kerner_size=(5,5), stride=(2,2), padding=(2,2))\n","    self.relu1 = nn.ReLU()\n","    self.bn1 = nn.BatchNorm2d(8)\n","    init.kaiming_normal_(self.conv1.weight, a=0.1)\n","    self.conv1.bais.data.zero_()\n","    conv_layers += [self.conv1, self.relu1, self.bn1]\n","\n","     # Second Convolution Block\n","    self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    self.relu2 = nn.ReLU()\n","    self.bn2 = nn.BatchNorm2d(16)\n","    init.kaiming_normal_(self.conv2.weight, a=0.1)\n","    self.conv2.bias.data.zero_()\n","    conv_layers += [self.conv2, self.relu2, self.bn2]\n","\n","    # Second Convolution Block\n","    self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    self.relu3 = nn.ReLU()\n","    self.bn3 = nn.BatchNorm2d(32)\n","    init.kaiming_normal_(self.conv3.weight, a=0.1)\n","    self.conv3.bias.data.zero_()\n","    conv_layers += [self.conv3, self.relu3, self.bn3]\n","\n","    # Second Convolution Block\n","    self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    self.relu4 = nn.ReLU()\n","    self.bn4 = nn.BatchNorm2d(64)\n","    init.kaiming_normal_(self.conv4.weight, a=0.1)\n","    self.conv4.bias.data.zero_()\n","    conv_layers += [self.conv4, self.relu4, self.bn4]\n","\n","    # Linear Classi\n","    self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n","    self.lin = nn.Linear(in_features=64, out_features=10)\n","\n","    # Wrap the Convolutional Blocks\n","\n","    self.conv = nn.Sequential(*conv_layers)\n","\n","  def forward(self, x):\n","    # Run the convolutional blocks\n","    x = self.conv(x)\n","\n","    # Adaptive pool and flatten for input to linear layer\n","    x = self.ap(x)\n","    x = x.view(x.shape[0], -1)\n","\n","    # Linear layer\n","    x = self.lin(x)\n","\n","    # Final output\n","    return x\n","\n","myModel = AudioClassifier()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","myModel = myModel.to(device)\n","\n","# Chck that if is on cuda\n","#next(myModel.parameters()).device\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qxn8zKHWHz0R","executionInfo":{"status":"ok","timestamp":1699372002331,"user_tz":-330,"elapsed":5,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}},"outputId":"4352bb2c-bae9-4b48-ddd6-d2db92423e39"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","source":["def training(model, train_dl, num_epochs):\n","  # Loss function, optimizer and schedular\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n","                                                  max_lr=0.001,\n","                                                  steps_per_epoch=int(len(train_dl)),\n","                                                  epochs=num_epochs,\n","                                                  anneal_strategy='linear')\n","\n","  for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    correction_prediction = 0\n","    total_prediction = 0\n","\n","\n","    for i, data in enumerate(train_dl):\n","      inputs, labels = data[0].to(device), data[1].to(device)\n","\n","      inputs_m, inputs_s = inputs.mean(), inputs.std()\n","      inputs = (inputs - inputs_m) / inputs_s\n","\n","      optimizer.zero_grad()\n","\n","      # forwared + backward + optimize\n","\n","      outputs = model(inputs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","      scheduler.step()\n","\n","      running_loss = loss.item()\n","\n","      _, prediction = torch.max(outputs,1)\n","      correct_prediction += (prediction == labels).sum().item()\n","      total_prediction += prediction.shape[0]\n","\n","      if i % 10 == 0:\n","        print(f'{epoch+1}, {i+1}, loss: {running_loss / 10}')\n","\n","    num_batches = len(train_dl)\n","    avg_loss = running_loss / num_batches\n","    acc = correct_prediction/total_prediction\n","    print(f'epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n","\n","  print('Finished Training')"],"metadata":{"id":"FbPvnobgJsKf","executionInfo":{"status":"ok","timestamp":1699372008099,"user_tz":-330,"elapsed":493,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["def inference(model, val_dl):\n","  correct_prediction = 0\n","  total_prediction = 0\n","\n","  with torch.no_grad():\n","    for data in val_dl:\n","\n","      inputs, labels = data[0].to(device), data[1].to(device)\n","\n","      # Normalize the inputs\n","      inputs_m, inputs_s = inputs.mean(), inputs.std()\n","      inputs = (inputs - inputs_m) / inputs_s\n","\n","\n","      outputs = model(inputs)\n","\n","      _, prediction = torch.max(outputs, 1)\n","      correct_prediction += (prediction == labels).sum().item()\n","      total_prediction += prediction.shape[0]\n","\n","\n","  acc = correct_prediction/total_prediction\n","  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n","\n","inference(myModel, val_dl)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500},"id":"ipQypAOBR8vB","executionInfo":{"status":"error","timestamp":1699372012301,"user_tz":-330,"elapsed":413,"user":{"displayName":"Venkata Ravuri","userId":"12407771891952084347"}},"outputId":"3e23cc9c-d4bc-40b6-e28a-37fa281294d1"},"execution_count":57,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-b31d33fc3a01>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {acc:.2f}, Total items: {total_prediction}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-57-b31d33fc3a01>\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, val_dl)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-53-45a41a2aae5e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mshift_aud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdur_aud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_pct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0msgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectro_gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshift_aud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0maug_sgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectro_gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_mask_pct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_freq_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_time_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-52-52b1904311aa>\u001b[0m in \u001b[0;36mspectro_gram\u001b[0;34m(aud, n_mels, n_fft, hop_len)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Convert to decibels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmplitudeToDB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_db\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/transforms/_transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecibel\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \"\"\"\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamplitude_to_DB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py\u001b[0m in \u001b[0;36mamplitude_to_DB\u001b[0;34m(x, multiplier, amin, db_multiplier, top_db)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecibel\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mx_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiplier\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m     \u001b[0mx_db\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmultiplier\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdb_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: clamp() received an invalid combination of arguments - got (MelSpectrogram, min=float), but expected one of:\n * (Tensor input, Tensor min, Tensor max, *, Tensor out)\n * (Tensor input, Number min, Number max, *, Tensor out)\n"]}]}]}