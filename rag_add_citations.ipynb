{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyNQxkqjHcEGcXfHbObdM2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkataravuri/ai-ml-models/blob/main/rag_add_citations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source\n",
        "\n",
        "https://python.langchain.com/docs/how_to/qa_citations/"
      ],
      "metadata": {
        "id": "SF5BR4o0j1hR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgs6e0ppjm8n"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain-openai langchain-anthropic langchain-community wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('ANTHROPIC_API_KEY')"
      ],
      "metadata": {
        "id": "oCi-N5mnkFAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "MgaG-fG7kRd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import WikipediaRetriever\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = (\n",
        "    \"You're a helpful AI assistant. Given a user question \"\n",
        "    + \"and some Wikipedia article snippet, answer the user \"\n",
        "    + \"question. If none of the articles answer the question, \"\n",
        "    + \"just say you don't know.\"\n",
        "    + \"\\n\\nHere are the Wikipedia articles: \"\n",
        "    + \"{context}\"\n",
        ")\n",
        "\n",
        "retriever = WikipediaRetriever(top_k_results=6, doc_content_chars_max=2000)\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "prompt.pretty_print()"
      ],
      "metadata": {
        "id": "efcIRtkekfmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def format_docs(docs: List[Document]) -> str:\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain_from_docs = (\n",
        "    RunnablePassthrough.assign(\n",
        "        context=retriever.with_fallbacks([format_docs]).stream\n",
        "    )\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "retrieve_docs = (lambda x: x[\"input\"]) | retriever\n",
        "\n",
        "chain = RunnablePassthrough.assign(\n",
        "    input=retrieve_docs\n",
        ") | rag_chain_from_docs"
      ],
      "metadata": {
        "id": "X2PSgzv5kpzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke(\"input\": \"What is the capital of France?\")\n",
        "print(result.keys())\n",
        "print(result[\"context\"][0])\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "id": "_GwOLEB4n4ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "claass CitedAnswer(BaseMode):\n",
        "  \"\"\"Answer the user question based only on the given sources, and cite the sources used.\"\"\"\n",
        "\n",
        "  answer: str = Field(\n",
        "      ...,\n",
        "      description=\"The answer to the user question, which is based only on the given sources.\"\n",
        "  )\n",
        "  citations: List[str] = Field(\n",
        "      ...,\n",
        "      description=\"The integer IDs of the SPECIFIC sources which justify the answer.\"\n",
        "  )"
      ],
      "metadata": {
        "id": "dNaq7SOyoTJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm = llm.with_structured_output(CitedAnswer)\n",
        "\n",
        "example_q = \"\"\"What Brain's height?\n",
        "\n",
        "Source: 1\n",
        "Information: Suzy is 6'2\"\n",
        "\n",
        "Souce: 2\n",
        "Information: Jeremiah is blonde\n",
        "\n",
        "Source: 3\n",
        "Information: Brian is 3 inchers shorter than Suzy\"\"\"\n",
        "\n",
        "result = structured_llm.invoke(example_q)\n",
        "print(result.answer)\n",
        "print(result.citations)"
      ],
      "metadata": {
        "id": "WcMT_W1kpHs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs_with_id(docs: List[Document]) -> str:\n",
        "  formatted = [\n",
        "      f\"Source ID: {i} \\nArticle Title: {doc.metadata['title']}\\nArticle Snippet: {doc.page_content}\"\n",
        "      for i, doc in enumerate(docs)\n",
        "  ]\n",
        "\n",
        "rag_chain_from_docs = (\n",
        "    RunnablePassthrough.assign(\n",
        "        context=(lamda x: format_docs_with_id(x[\"context\"]))\n",
        "    )\n",
        "    | prompt\n",
        "    | structured_llm\n",
        " )\n",
        "\n",
        "retreive_docs = (lambda x: x[\"input\"]) | retriever\n",
        "\n",
        "chain = RunnablePassthrough.assign(\n",
        "    context=retrieve_docs\n",
        ") | rag_chain_from_docs"
      ],
      "metadata": {
        "id": "b6i7CGxM3EIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke(\"input\": \"How fast are cheethas?\")\n",
        "print(result.answer)\n",
        "print(result.citations)"
      ],
      "metadata": {
        "id": "DC9N6yqE4lzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}